<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>assignment4 API documentation</title>
<meta name="description" content="Last modified on Thu Nov
23 16:17:23 2021
Skeleton file for exact inference.
@author: jpoeppel" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>assignment4</code></h1>
</header>
<section id="section-intro">
<p>Last modified on Thu Nov
23 16:17:23 2021
Skeleton file for exact inference.
@author: jpoeppel</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3
# -*- coding: utf-8 -*-
&#34;&#34;&#34;
Last modified on Thu Nov  23 16:17:23 2021
Skeleton file for exact inference.
@author: jpoeppel
&#34;&#34;&#34;

&#34;&#34;&#34;
    There are minor changes to the ccbase compared to assignment 3:
    ccbase.networks now contains a subclass BayesianNetwork, which so far does
    not add any additional information. 
    I also added a &#34;DiscreteVariable&#34; class to ccbase.nodes, which subclasses
    the old Node class to better represent variables in a Bayesian Network,
    in particular with respect to their outcomes. See the docs or the functions for
    creating example graphs for details.
    Furthermore, a reference implementation of the Factor class can now be 
    found in ccbase.factor.
    The known classes Graph and Node have themselves not been changed and are
    just as you have seen in the previous assignments.
&#34;&#34;&#34;

from typing import Union, Optional, List, Dict, Iterable, Tuple

from ccbase.networks import BayesianNetwork
from ccbase.nodes import DiscreteVariable
from ccbase.factor import Factor
import numpy as np


########
#      #
# Ex 1 #
#      #
########
def get_elimination_ordering(bn: BayesianNetwork) -&gt; List[str]:
    &#34;&#34;&#34;
        Computes an elimination order of all the variables in the network
        according to the MinFillOrder heuristic.

        Parameters
        ---------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        
        Returns
        -------
        [str]
            A list containing the names of all the nodes in the network
            bn, in an order following a suitable heuristic.
            
        Remark:
            Exercise 1 Task 2 does not require you to write code, instead
            you should describe another heuristic and explain how it works
            and what the differences are with respect to the MinFillOrder.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 1.1&#34;)

########
#      #
# Ex 2 #
#      #
########

def initialize_factors(bn: BayesianNetwork, evidence: Optional[Dict[str, str]]) -&gt; Iterable[Factor]:
    &#34;&#34;&#34;
        Creates and returns a factor for every node in the Bayesian network initialized according
        to the node&#39;s CPTs while taking the given evidence into account.

        Parameters
        ---------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        evidence: Dict[str, str], optional
            A dictionary containing the evidence variables as keys and their
            observed outcomes as values. 

        Returns
        -------
            Iterable[Factor]
            An iterable (e.g. a list or a set) containing a factor for every 
            node in the BayesianNetwork, properly initialized.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.1&#34;)

def sum_product_elim_var(factors: Iterable[Factor], variable: str) -&gt; Iterable[Factor]:
    &#34;&#34;&#34;
        Eliminates the given variable from the given factors via marginalization.

        Parameters
        ----------
        factors: iterable of ccbase.factor.Factor
            Any iterable of factors from which the variable is to be removed
        variable: String
            The variable to be eliminated.

        Returns
        --------
        iterable of ccbase.factor.Factor
            The remaining factors that do no longer include the eliminated variable.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.2&#34;)


def calculate_probabilities(bn: BayesianNetwork, 
                        variables: Union[str, DiscreteVariable], 
                        evidence: Optional[Dict[str,str]] = None) -&gt; Factor:
    &#34;&#34;&#34;
        Calculates P(variables|evidence) for all outcome combinations of
        variables  (i.e. you should return a table similar to a cpt, 
        only representing a joint distribution in this case.)
        
        Example: Calling calculate_marginals([&#34;rain&#34;, &#34;winter&#34;], 
                                                {&#34;sprinkler&#34;:&#34;True&#34;})
        should return a Factor representing P(rain,winter|sprinkler=True). 
        
        Parameters
        ----------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        variables: [str, Node]
            List containing the nodes, or their names of the variables of 
            interest.
            (Hint: Your code can/should assume, that a name is passed and
            simply retrieve the node manually, so that you do not have
            to differentiate these two cases.)
        evidence: Dict[str, str], optional
            A dictionary containing the evidence variables as keys and their
            observed outcomes as values. If evidence is not given, the prior
            marginals should be computed.
            
        Returns
        -------
        ccbase.factor.Factor
            A Factor over the specified variables, specifying the joint (posterior) probability
            of these variables.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.3&#34;)
            

########
#      #
# Ex 3 #
#      #
########     

def maximize_out(factor: Factor, variable: str) -&gt; Factor:
    &#34;&#34;&#34;
        Takes a factor and removes the given variable from that
        factor via maximization, according to the definition in
        Darwiche: Modeling and Reasoning with Bayes:

        $$ (max_x f)(\mathbf{y}) = max_x f(x, \mathbf{y}) $$

        Parameters
        ----------
        factor: ccbase.factor.Factor
            The factor from which to remove the variable.
        variable: String
            The name of the variable to be maxmized out.

        Returns
        --------
        ccbase.factor.Factor
            A new factor that results from maximizing out the 
            variable from the initial factor.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.1&#34;)


def max_product_elim_var(factors: Iterable[Factor], variable: str) -&gt; Tuple[Iterable[Factor], Factor]:
    &#34;&#34;&#34;
        Eliminates the given variable from the given factors via maximization.
        You will want to return BOTH the iterable (e.g. list) of remaining facotrs
        as well as a factor combining all factors that contained the eliminated 
        variable.

        Parameters
        ----------
        factors: iterable of ccbase.factor.Factor
            Any iterable of factors from which the variable is to be removed
        variable: String
            The variable to be eliminated.

        Returns
        --------
        iterable of ccbase.factor.Factor
            The remaining factors that do no longer include the eliminated variable.
        ccbase.factor.Factor
            The factor combining all factors containing the variable, i.e. the &#34;product-factor&#34;
            before the maximization. This is helpful for traceback function.
    &#34;&#34;&#34; 
    raise NotImplementedError(&#34;TODO Exercise 3.2&#34;)

def traceback(factors: Dict[str, Factor], order: List[str]) -&gt; Dict[str,str]:
    &#34;&#34;&#34;
        Computes the optimal instantiation of all variables based on
        the given factors and elimination order.

        Parameters
        ----------
        factors: dict of ccbase.factor.Factor
            A dictionary containing variable-name:Factor pairs, where each 
            Factor is the Factor from which the variable was removed via
            maximization.
        order: list of String
            The order in which the variables have been eliminated.

        Returns
        -------
        dict
            A dictionary containing variable:outcome pairs representing the
            MPE.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.3&#34;)


def calculate_MAP(bn: BayesianNetwork, 
                evidence: Optional[Union[str, DiscreteVariable]] =None) -&gt; Tuple[float, Dict[str,str]]:
    &#34;&#34;&#34;
        Function calculating the most probable explanation (MPE) as well as its
        probability given potential evidence.

        Parameters
        -----------
        bn: ccbase.networks.BayesianNetwork
            The BayesianNetwork for which the MAP is to be computed.
        evidence: {Node/Nodename: Outcome}, optional
            The evidence which needs to be considered when computing the MAP.

        Returns
        --------
        float
            The probability of the MPE.
        dict
            A dictionary representing the MPE as Variable:Outcome pairs for all
            variables in the network.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.4&#34;)
    



######
#
# Example networks
#
######


def get_simple_net():
    &#34;&#34;&#34;
        Helper function to generate a simple BayesianNetwork with binary
        variables.
    &#34;&#34;&#34;
    net = BayesianNetwork()

    #Create the discrete variables that should be contained in the network
    node_winter = DiscreteVariable(&#34;winter&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_sprinkler = DiscreteVariable(&#34;sprinkler&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_rain = DiscreteVariable(&#34;rain&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_grass = DiscreteVariable(&#34;wet_grass&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_road = DiscreteVariable(&#34;slippery_road&#34;, [&#34;True&#34;, &#34;False&#34;])

    #Add the nodes to the network
    net.add_node(node_winter)
    net.add_node(node_sprinkler)
    net.add_node(node_rain)
    net.add_node(node_grass)
    net.add_node(node_road)

    #Setup the relationships between the variables
    net.add_edge(node_winter, node_sprinkler)
    net.add_edge(node_winter, node_rain)
    net.add_edge(node_sprinkler, node_grass)
    net.add_edge(node_rain, node_grass)
    net.add_edge(node_rain, node_road)
    
    #Setup the (conditional) probability tables.
    #Make sure that you set these tables AFTER you specify the edges, as adding
    #an edge would require changes to the cpts!
    #Also note, that currently you need ot be careful to specify the table in
    #the correct format, as mentioned in tutorial session 3!
    
    # This corresponds to P(winter=True) = 0.6 and P(winter=False) = 0.4
    node_winter.set_probability_table(np.array([0.6, 0.4]))
    
    # As sprinkler has 1 parent (winter) this corresponds to:
    # P(sprinkler=True|winter=True) = 0.2
    # P(sprinkler=True|winter=False) = 0.75
    # P(sprinkler=False|winter=True) = 0.8
    # P(sprinkler=False|winter=False) = 0.25
    
    node_sprinkler.set_probability_table(np.array([[0.2, 0.75], 
                                                   [0.8, 0.25]]))
    
    # Analogue to the sprinkler node
    node_rain.set_probability_table(np.array([[0.8, 0.1], 
                                              [0.2, 0.9]]))
    
    # Analogue to the sprinkler node, just with rain as parent
    node_road.set_probability_table(np.array([[0.7, 0.0], 
                                              [0.3, 1.0]]))
    
    # Grass has 2 parents, sprinkler and rain (in that order as specified above!)
    # Accordingly this corresponds to:
    # P(grass=True|sprinkler=True, rain=True)= 0.95
    # P(grass=True|sprinkler=True, rain=False)= 0.1
    # P(grass=True|sprinkler=False, rain=True)= 0.8
    # P(grass=True|sprinkler=False, rain=False)= 0.0
    # P(grass=False|sprinkler=True, rain=True)= 0.05
    # P(grass=False|sprinkler=True, rain=False)= 0.9
    # P(grass=False|sprinkler=False, rain=True)= 0.2
    # P(grass=False|sprinkler=False, rain=False)= 1.0
    node_grass.set_probability_table(np.array([
                                            [ #Block for grass=True 
                                                [0.95, 0.1], #sprinkler=True
                                                [0.8, 0.0 ] #sprinkler = False
                                            ], 
                                            [ # Block for grass=False
                                                [0.05, 0.9], #sprinkler=True
                                                [0.2, 1.0] #sprinkler=False
                                            ]]))
    
    
    
    return net

def get_non_binary_net():
    &#34;&#34;&#34;
        Helper function to generate a simple BayesianNetwork with
        non-binary variables.
    &#34;&#34;&#34;
    net = BayesianNetwork()
    
    node_john = DiscreteVariable(&#34;john&#34;, [&#34;Calling&#34;, &#34;Not_calling&#34;])
    node_burglary = DiscreteVariable(&#34;burglary&#34;, [&#34;Intruder&#34;, &#34;Safe&#34;])
    node_alarm = DiscreteVariable(&#34;alarm&#34;, [&#34;Ringing&#34;, &#34;Silent&#34;, &#34;Broken&#34;])
    
    net.add_node(node_john)
    net.add_node(node_burglary)
    net.add_node(node_alarm)
    
    net.add_edge(node_alarm, node_john)
    net.add_edge(node_burglary, node_john)
    
    node_burglary.set_probability_table(np.array([0.4,0.6]))
    node_alarm.set_probability_table(np.array([0.2,0.3,0.5]))
    node_john.set_probability_table(np.array([
                                                [
                                                    [0.8, 0.6], #alarm=ringing
                                                    [0.7, 0.1], #alarm=silent
                                                    [0.5, 0.2] #alarm=broken
                                                ],
                                                [
                                                    [0.2, 0.4],
                                                    [0.3, 0.9],
                                                    [0.5, 0.8]
                                                ]]))
    
    return net


## test cases
if __name__ == &#34;__main__&#34;:
    
    net1 = get_simple_net()

    print(&#34;Elimination order: &#34;, get_elimination_ordering(net1))
    
    # Example of how to construct factors from a DiscreteVariables
    node_rain = net1.nodes[&#34;rain&#34;]
    # Note that I am using the classmethod here, i.e. I call the method on
    # the class, not on any instance of it!
    rain_factor = Factor.from_node(node_rain)
    winter_factor = Factor.from_node(net1.nodes[&#34;winter&#34;])
    
    # Calling sum_product_elim_var only with factors not containing the
    # variable should not change anything
    assert sum_product_elim_var([rain_factor], &#34;wet_grass&#34;)[0] == rain_factor
    # The trivial case of having only 1 factor with only 1 variable, results in an
    # empty factor with value 1 in this case.
    assert sum_product_elim_var([winter_factor], &#34;winter&#34;)[0].potential({}) == 1
    
    #Simplest testcase. We use allclose instead of equal to avoid precisiion errors.
    res = calculate_probabilities(net1, [&#34;winter&#34;])
    np.testing.assert_allclose(res.potential({&#34;winter&#34;:&#34;True&#34;}), 0.6)
    # The reference Factor class stores the values in a np.array called &#34;potentials&#34;, 
    # we can check the entrire result using:
    np.testing.assert_allclose(res.potentials, np.array([0.6,0.4]))

    # maximize_out will remove variables from the factors
    assert rain_factor.variable_order == [&#34;rain&#34;, &#34;winter&#34;]
    res_factor = maximize_out(rain_factor, &#34;winter&#34;)
    assert res_factor.variable_order == [&#34;rain&#34;]

    # Max product will also only influence factors that contain the variable
    assert max_product_elim_var([rain_factor], &#34;wet_grass&#34;)[0][0] == rain_factor
    # Similarly to sum_product_elim_var, max will also produce an empty factor
    # when the last variable is removed, but the potential will not be 1 but the
    # max
    assert max_product_elim_var([winter_factor], &#34;winter&#34;)[0][0].potential({}) == 0.6

    # The traceback function is more difficult to test by itself as it requires
    # suitable factors.

    # You should test your MAP results using your calculate_probabilities function
    mpe_prob, mpe = calculate_MAP(net1)
    print(&#34;The MAP is {} with probability: {}&#34;.format(mpe, mpe_prob))
    joint_posterior_factor = calculate_probabilities(net1, list(mpe.keys()))
    print(&#34;Probability for the mpe: {}&#34;.format(joint_posterior_factor.potential(mpe)))
    # Similarly with evidence!

    # Some more interesting examples, you would need to calculate the correct
    # results yourself, or use, e.g. samIam to compare
    
    print(&#34;Tests for net 1&#34;)
    print(&#34;=&#34;*20)
    
    prior_slippery = calculate_probabilities(net1, [&#34;slippery_road&#34;])
    # We can call a Factor just like a function, which will call the &#34;potential&#34; function.
    print(&#34;Prior marginal for node slippery_road=False: {}&#34;.format(prior_slippery({&#34;slippery_road&#34;:&#34;False&#34;})))

    posterior_grass = calculate_probabilities(net1, [&#34;wet_grass&#34;], {&#34;slippery_road&#34;:&#34;True&#34;})
    print(&#34;Posterior marginal for node wet_grass=False given slippery_road=True: {}&#34;.format(posterior_grass({&#34;wet_grass&#34;: &#34;False&#34;})))
    
    
    posterior_rain_winter = calculate_probabilities(net1, [&#34;rain&#34;, &#34;winter&#34;], {&#34;sprinkler&#34;:&#34;True&#34;})
    print(&#34;Posterior marginal for nodes rain=True and winter=False, given sprinkler=True: {}&#34;.format(posterior_rain_winter({&#34;rain&#34;:&#34;True&#34;,&#34;winter&#34;:&#34;False&#34;})))


    # Feel free to construct more testcases, e.g. with the non_binary, multivariate network 

    # print(&#34;Tests for net 2&#34;)
    # print(&#34;===============&#34;)
    
    # net2 =  get_non_binary_net()
    
    # print(&#34;Prior for John=Not_calling: &#34;, calculate_probabilities(net2, [&#34;john&#34;])({&#34;john&#34;:&#34;Not_calling&#34;}))
    # print(&#34;Prior for burglary=Intruder: &#34;, calculate_probabilities(net2, [&#34;burglary&#34;])({&#34;burglary&#34;:&#34;Intruder&#34;}))
    # print(&#34;Prior for alarm=Broken: &#34;, calculate_probabilities(net2, [&#34;alarm&#34;])({&#34;alarm&#34;:&#34;Broken&#34;}))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="assignment4.calculate_MAP"><code class="name flex">
<span>def <span class="ident">calculate_MAP</span></span>(<span>bn: <a title="ccbase.networks.BayesianNetwork" href="ccbase/networks.html#ccbase.networks.BayesianNetwork">BayesianNetwork</a>, evidence: Union[str, <a title="ccbase.nodes.DiscreteVariable" href="ccbase/nodes.html#ccbase.nodes.DiscreteVariable">DiscreteVariable</a>, ForwardRef(None)] = None) ‑> Tuple[float, Dict[str, str]]</span>
</code></dt>
<dd>
<div class="desc"><p>Function calculating the most probable explanation (MPE) as well as its
probability given potential evidence.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bn</code></strong> :&ensp;<code><a title="ccbase.networks.BayesianNetwork" href="ccbase/networks.html#ccbase.networks.BayesianNetwork">BayesianNetwork</a></code></dt>
<dd>The BayesianNetwork for which the MAP is to be computed.</dd>
<dt><strong><code>evidence</code></strong> :&ensp;<code>{Node/Nodename: Outcome}</code>, optional</dt>
<dd>The evidence which needs to be considered when computing the MAP.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The probability of the MPE.</dd>
<dt><code>dict</code></dt>
<dd>A dictionary representing the MPE as Variable:Outcome pairs for all
variables in the network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_MAP(bn: BayesianNetwork, 
                evidence: Optional[Union[str, DiscreteVariable]] =None) -&gt; Tuple[float, Dict[str,str]]:
    &#34;&#34;&#34;
        Function calculating the most probable explanation (MPE) as well as its
        probability given potential evidence.

        Parameters
        -----------
        bn: ccbase.networks.BayesianNetwork
            The BayesianNetwork for which the MAP is to be computed.
        evidence: {Node/Nodename: Outcome}, optional
            The evidence which needs to be considered when computing the MAP.

        Returns
        --------
        float
            The probability of the MPE.
        dict
            A dictionary representing the MPE as Variable:Outcome pairs for all
            variables in the network.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.4&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.calculate_probabilities"><code class="name flex">
<span>def <span class="ident">calculate_probabilities</span></span>(<span>bn: <a title="ccbase.networks.BayesianNetwork" href="ccbase/networks.html#ccbase.networks.BayesianNetwork">BayesianNetwork</a>, variables: Union[str, <a title="ccbase.nodes.DiscreteVariable" href="ccbase/nodes.html#ccbase.nodes.DiscreteVariable">DiscreteVariable</a>], evidence: Optional[Dict[str, str]] = None) ‑> <a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></span>
</code></dt>
<dd>
<div class="desc"><p>Calculates P(variables|evidence) for all outcome combinations of
variables
(i.e. you should return a table similar to a cpt,
only representing a joint distribution in this case.)</p>
<p>Example: Calling calculate_marginals(["rain", "winter"],
{"sprinkler":"True"})
should return a Factor representing P(rain,winter|sprinkler=True). </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bn</code></strong> :&ensp;<code>BayesianNetwork</code></dt>
<dd>The BayesianNetwork for which the elimination order is to be
computed.</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>[str, Node]</code></dt>
<dd>List containing the nodes, or their names of the variables of
interest.
(Hint: Your code can/should assume, that a name is passed and
simply retrieve the node manually, so that you do not have
to differentiate these two cases.)</dd>
<dt><strong><code>evidence</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>A dictionary containing the evidence variables as keys and their
observed outcomes as values. If evidence is not given, the prior
marginals should be computed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>A Factor over the specified variables, specifying the joint (posterior) probability
of these variables.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_probabilities(bn: BayesianNetwork, 
                        variables: Union[str, DiscreteVariable], 
                        evidence: Optional[Dict[str,str]] = None) -&gt; Factor:
    &#34;&#34;&#34;
        Calculates P(variables|evidence) for all outcome combinations of
        variables  (i.e. you should return a table similar to a cpt, 
        only representing a joint distribution in this case.)
        
        Example: Calling calculate_marginals([&#34;rain&#34;, &#34;winter&#34;], 
                                                {&#34;sprinkler&#34;:&#34;True&#34;})
        should return a Factor representing P(rain,winter|sprinkler=True). 
        
        Parameters
        ----------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        variables: [str, Node]
            List containing the nodes, or their names of the variables of 
            interest.
            (Hint: Your code can/should assume, that a name is passed and
            simply retrieve the node manually, so that you do not have
            to differentiate these two cases.)
        evidence: Dict[str, str], optional
            A dictionary containing the evidence variables as keys and their
            observed outcomes as values. If evidence is not given, the prior
            marginals should be computed.
            
        Returns
        -------
        ccbase.factor.Factor
            A Factor over the specified variables, specifying the joint (posterior) probability
            of these variables.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.3&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.get_elimination_ordering"><code class="name flex">
<span>def <span class="ident">get_elimination_ordering</span></span>(<span>bn: <a title="ccbase.networks.BayesianNetwork" href="ccbase/networks.html#ccbase.networks.BayesianNetwork">BayesianNetwork</a>) ‑> List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Computes an elimination order of all the variables in the network
according to the MinFillOrder heuristic.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bn</code></strong> :&ensp;<code>BayesianNetwork</code></dt>
<dd>The BayesianNetwork for which the elimination order is to be
computed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>[str]
A list containing the names of all the nodes in the network
bn, in an order following a suitable heuristic.</p>
<h2 id="remark">Remark</h2>
<p>Exercise 1 Task 2 does not require you to write code, instead
you should describe another heuristic and explain how it works
and what the differences are with respect to the MinFillOrder.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_elimination_ordering(bn: BayesianNetwork) -&gt; List[str]:
    &#34;&#34;&#34;
        Computes an elimination order of all the variables in the network
        according to the MinFillOrder heuristic.

        Parameters
        ---------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        
        Returns
        -------
        [str]
            A list containing the names of all the nodes in the network
            bn, in an order following a suitable heuristic.
            
        Remark:
            Exercise 1 Task 2 does not require you to write code, instead
            you should describe another heuristic and explain how it works
            and what the differences are with respect to the MinFillOrder.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 1.1&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.get_non_binary_net"><code class="name flex">
<span>def <span class="ident">get_non_binary_net</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to generate a simple BayesianNetwork with
non-binary variables.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_non_binary_net():
    &#34;&#34;&#34;
        Helper function to generate a simple BayesianNetwork with
        non-binary variables.
    &#34;&#34;&#34;
    net = BayesianNetwork()
    
    node_john = DiscreteVariable(&#34;john&#34;, [&#34;Calling&#34;, &#34;Not_calling&#34;])
    node_burglary = DiscreteVariable(&#34;burglary&#34;, [&#34;Intruder&#34;, &#34;Safe&#34;])
    node_alarm = DiscreteVariable(&#34;alarm&#34;, [&#34;Ringing&#34;, &#34;Silent&#34;, &#34;Broken&#34;])
    
    net.add_node(node_john)
    net.add_node(node_burglary)
    net.add_node(node_alarm)
    
    net.add_edge(node_alarm, node_john)
    net.add_edge(node_burglary, node_john)
    
    node_burglary.set_probability_table(np.array([0.4,0.6]))
    node_alarm.set_probability_table(np.array([0.2,0.3,0.5]))
    node_john.set_probability_table(np.array([
                                                [
                                                    [0.8, 0.6], #alarm=ringing
                                                    [0.7, 0.1], #alarm=silent
                                                    [0.5, 0.2] #alarm=broken
                                                ],
                                                [
                                                    [0.2, 0.4],
                                                    [0.3, 0.9],
                                                    [0.5, 0.8]
                                                ]]))
    
    return net</code></pre>
</details>
</dd>
<dt id="assignment4.get_simple_net"><code class="name flex">
<span>def <span class="ident">get_simple_net</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to generate a simple BayesianNetwork with binary
variables.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_simple_net():
    &#34;&#34;&#34;
        Helper function to generate a simple BayesianNetwork with binary
        variables.
    &#34;&#34;&#34;
    net = BayesianNetwork()

    #Create the discrete variables that should be contained in the network
    node_winter = DiscreteVariable(&#34;winter&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_sprinkler = DiscreteVariable(&#34;sprinkler&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_rain = DiscreteVariable(&#34;rain&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_grass = DiscreteVariable(&#34;wet_grass&#34;, [&#34;True&#34;, &#34;False&#34;])
    node_road = DiscreteVariable(&#34;slippery_road&#34;, [&#34;True&#34;, &#34;False&#34;])

    #Add the nodes to the network
    net.add_node(node_winter)
    net.add_node(node_sprinkler)
    net.add_node(node_rain)
    net.add_node(node_grass)
    net.add_node(node_road)

    #Setup the relationships between the variables
    net.add_edge(node_winter, node_sprinkler)
    net.add_edge(node_winter, node_rain)
    net.add_edge(node_sprinkler, node_grass)
    net.add_edge(node_rain, node_grass)
    net.add_edge(node_rain, node_road)
    
    #Setup the (conditional) probability tables.
    #Make sure that you set these tables AFTER you specify the edges, as adding
    #an edge would require changes to the cpts!
    #Also note, that currently you need ot be careful to specify the table in
    #the correct format, as mentioned in tutorial session 3!
    
    # This corresponds to P(winter=True) = 0.6 and P(winter=False) = 0.4
    node_winter.set_probability_table(np.array([0.6, 0.4]))
    
    # As sprinkler has 1 parent (winter) this corresponds to:
    # P(sprinkler=True|winter=True) = 0.2
    # P(sprinkler=True|winter=False) = 0.75
    # P(sprinkler=False|winter=True) = 0.8
    # P(sprinkler=False|winter=False) = 0.25
    
    node_sprinkler.set_probability_table(np.array([[0.2, 0.75], 
                                                   [0.8, 0.25]]))
    
    # Analogue to the sprinkler node
    node_rain.set_probability_table(np.array([[0.8, 0.1], 
                                              [0.2, 0.9]]))
    
    # Analogue to the sprinkler node, just with rain as parent
    node_road.set_probability_table(np.array([[0.7, 0.0], 
                                              [0.3, 1.0]]))
    
    # Grass has 2 parents, sprinkler and rain (in that order as specified above!)
    # Accordingly this corresponds to:
    # P(grass=True|sprinkler=True, rain=True)= 0.95
    # P(grass=True|sprinkler=True, rain=False)= 0.1
    # P(grass=True|sprinkler=False, rain=True)= 0.8
    # P(grass=True|sprinkler=False, rain=False)= 0.0
    # P(grass=False|sprinkler=True, rain=True)= 0.05
    # P(grass=False|sprinkler=True, rain=False)= 0.9
    # P(grass=False|sprinkler=False, rain=True)= 0.2
    # P(grass=False|sprinkler=False, rain=False)= 1.0
    node_grass.set_probability_table(np.array([
                                            [ #Block for grass=True 
                                                [0.95, 0.1], #sprinkler=True
                                                [0.8, 0.0 ] #sprinkler = False
                                            ], 
                                            [ # Block for grass=False
                                                [0.05, 0.9], #sprinkler=True
                                                [0.2, 1.0] #sprinkler=False
                                            ]]))
    
    
    
    return net</code></pre>
</details>
</dd>
<dt id="assignment4.initialize_factors"><code class="name flex">
<span>def <span class="ident">initialize_factors</span></span>(<span>bn: <a title="ccbase.networks.BayesianNetwork" href="ccbase/networks.html#ccbase.networks.BayesianNetwork">BayesianNetwork</a>, evidence: Optional[Dict[str, str]]) ‑> Iterable[<a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Creates and returns a factor for every node in the Bayesian network initialized according
to the node's CPTs while taking the given evidence into account.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>bn</code></strong> :&ensp;<code>BayesianNetwork</code></dt>
<dd>The BayesianNetwork for which the elimination order is to be
computed.</dd>
<dt><strong><code>evidence</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>A dictionary containing the evidence variables as keys and their
observed outcomes as values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code>Iterable[Factor]
An iterable (e.g. a list or a set) containing a factor for every 
node in the BayesianNetwork, properly initialized.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_factors(bn: BayesianNetwork, evidence: Optional[Dict[str, str]]) -&gt; Iterable[Factor]:
    &#34;&#34;&#34;
        Creates and returns a factor for every node in the Bayesian network initialized according
        to the node&#39;s CPTs while taking the given evidence into account.

        Parameters
        ---------
        bn: BayesianNetwork
            The BayesianNetwork for which the elimination order is to be 
            computed.
        evidence: Dict[str, str], optional
            A dictionary containing the evidence variables as keys and their
            observed outcomes as values. 

        Returns
        -------
            Iterable[Factor]
            An iterable (e.g. a list or a set) containing a factor for every 
            node in the BayesianNetwork, properly initialized.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.1&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.max_product_elim_var"><code class="name flex">
<span>def <span class="ident">max_product_elim_var</span></span>(<span>factors: Iterable[<a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>], variable: str) ‑> Tuple[Iterable[<a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>], <a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Eliminates the given variable from the given factors via maximization.
You will want to return BOTH the iterable (e.g. list) of remaining facotrs
as well as a factor combining all factors that contained the eliminated
variable.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>factors</code></strong> :&ensp;<code>iterable</code> of <code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>Any iterable of factors from which the variable is to be removed</dd>
<dt><strong><code>variable</code></strong> :&ensp;<code>String</code></dt>
<dd>The variable to be eliminated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>iterable</code> of <code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>The remaining factors that do no longer include the eliminated variable.</dd>
<dt><code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>The factor combining all factors containing the variable, i.e. the "product-factor"
before the maximization. This is helpful for traceback function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max_product_elim_var(factors: Iterable[Factor], variable: str) -&gt; Tuple[Iterable[Factor], Factor]:
    &#34;&#34;&#34;
        Eliminates the given variable from the given factors via maximization.
        You will want to return BOTH the iterable (e.g. list) of remaining facotrs
        as well as a factor combining all factors that contained the eliminated 
        variable.

        Parameters
        ----------
        factors: iterable of ccbase.factor.Factor
            Any iterable of factors from which the variable is to be removed
        variable: String
            The variable to be eliminated.

        Returns
        --------
        iterable of ccbase.factor.Factor
            The remaining factors that do no longer include the eliminated variable.
        ccbase.factor.Factor
            The factor combining all factors containing the variable, i.e. the &#34;product-factor&#34;
            before the maximization. This is helpful for traceback function.
    &#34;&#34;&#34; 
    raise NotImplementedError(&#34;TODO Exercise 3.2&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.maximize_out"><code class="name flex">
<span>def <span class="ident">maximize_out</span></span>(<span>factor: <a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>, variable: str) ‑> <a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></span>
</code></dt>
<dd>
<div class="desc"><p>Takes a factor and removes the given variable from that
factor via maximization, according to the definition in
Darwiche: Modeling and Reasoning with Bayes:</p>
<p>$$ (max_x f)(\mathbf{y}) = max_x f(x, \mathbf{y}) $$</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>factor</code></strong> :&ensp;<code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>The factor from which to remove the variable.</dd>
<dt><strong><code>variable</code></strong> :&ensp;<code>String</code></dt>
<dd>The name of the variable to be maxmized out.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>A new factor that results from maximizing out the
variable from the initial factor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def maximize_out(factor: Factor, variable: str) -&gt; Factor:
    &#34;&#34;&#34;
        Takes a factor and removes the given variable from that
        factor via maximization, according to the definition in
        Darwiche: Modeling and Reasoning with Bayes:

        $$ (max_x f)(\mathbf{y}) = max_x f(x, \mathbf{y}) $$

        Parameters
        ----------
        factor: ccbase.factor.Factor
            The factor from which to remove the variable.
        variable: String
            The name of the variable to be maxmized out.

        Returns
        --------
        ccbase.factor.Factor
            A new factor that results from maximizing out the 
            variable from the initial factor.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.1&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.sum_product_elim_var"><code class="name flex">
<span>def <span class="ident">sum_product_elim_var</span></span>(<span>factors: Iterable[<a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>], variable: str) ‑> Iterable[<a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Eliminates the given variable from the given factors via marginalization.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>factors</code></strong> :&ensp;<code>iterable</code> of <code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>Any iterable of factors from which the variable is to be removed</dd>
<dt><strong><code>variable</code></strong> :&ensp;<code>String</code></dt>
<dd>The variable to be eliminated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>iterable</code> of <code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>The remaining factors that do no longer include the eliminated variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum_product_elim_var(factors: Iterable[Factor], variable: str) -&gt; Iterable[Factor]:
    &#34;&#34;&#34;
        Eliminates the given variable from the given factors via marginalization.

        Parameters
        ----------
        factors: iterable of ccbase.factor.Factor
            Any iterable of factors from which the variable is to be removed
        variable: String
            The variable to be eliminated.

        Returns
        --------
        iterable of ccbase.factor.Factor
            The remaining factors that do no longer include the eliminated variable.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 2.2&#34;)</code></pre>
</details>
</dd>
<dt id="assignment4.traceback"><code class="name flex">
<span>def <span class="ident">traceback</span></span>(<span>factors: Dict[str, <a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a>], order: List[str]) ‑> Dict[str, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the optimal instantiation of all variables based on
the given factors and elimination order.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>factors</code></strong> :&ensp;<code>dict</code> of <code><a title="ccbase.factor.Factor" href="ccbase/factor.html#ccbase.factor.Factor">Factor</a></code></dt>
<dd>A dictionary containing variable-name:Factor pairs, where each
Factor is the Factor from which the variable was removed via
maximization.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>list</code> of <code>String</code></dt>
<dd>The order in which the variables have been eliminated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary containing variable:outcome pairs representing the
MPE.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def traceback(factors: Dict[str, Factor], order: List[str]) -&gt; Dict[str,str]:
    &#34;&#34;&#34;
        Computes the optimal instantiation of all variables based on
        the given factors and elimination order.

        Parameters
        ----------
        factors: dict of ccbase.factor.Factor
            A dictionary containing variable-name:Factor pairs, where each 
            Factor is the Factor from which the variable was removed via
            maximization.
        order: list of String
            The order in which the variables have been eliminated.

        Returns
        -------
        dict
            A dictionary containing variable:outcome pairs representing the
            MPE.
    &#34;&#34;&#34;
    raise NotImplementedError(&#34;TODO Exercise 3.3&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="assignment4.calculate_MAP" href="#assignment4.calculate_MAP">calculate_MAP</a></code></li>
<li><code><a title="assignment4.calculate_probabilities" href="#assignment4.calculate_probabilities">calculate_probabilities</a></code></li>
<li><code><a title="assignment4.get_elimination_ordering" href="#assignment4.get_elimination_ordering">get_elimination_ordering</a></code></li>
<li><code><a title="assignment4.get_non_binary_net" href="#assignment4.get_non_binary_net">get_non_binary_net</a></code></li>
<li><code><a title="assignment4.get_simple_net" href="#assignment4.get_simple_net">get_simple_net</a></code></li>
<li><code><a title="assignment4.initialize_factors" href="#assignment4.initialize_factors">initialize_factors</a></code></li>
<li><code><a title="assignment4.max_product_elim_var" href="#assignment4.max_product_elim_var">max_product_elim_var</a></code></li>
<li><code><a title="assignment4.maximize_out" href="#assignment4.maximize_out">maximize_out</a></code></li>
<li><code><a title="assignment4.sum_product_elim_var" href="#assignment4.sum_product_elim_var">sum_product_elim_var</a></code></li>
<li><code><a title="assignment4.traceback" href="#assignment4.traceback">traceback</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>